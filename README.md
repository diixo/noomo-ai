
# noomo-tokenizer


main.py - convert tokens from `gpt2`-model, that mapped on custom word-dictionary (db-full-58900.txt)

* Stored result tokenization from **gpt2**: output-gpt2.txt
* Stored result tokenization from **noomo**: output-cased.txt
